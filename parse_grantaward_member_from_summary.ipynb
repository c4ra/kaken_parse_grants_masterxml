{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KAKENからダウンロードしたXMLファイルをパースして、ローカルのMariaDBに保存するプログラム\n",
    "\n",
    "### ファイル構成\n",
    "\n",
    "4つのファイルでできています。部品を作る3つのファイルと、3つの部品を統合するファイルです。\n",
    "\n",
    "#### 部品を作る\n",
    "- parse_grantaward_main.ipynb\n",
    " - 研究課題のメインになる部分。課題番号、研究種目、開始年度、終了年度、直接経費金額など\n",
    "- parse_grantaward_institution_from_grantlist.ipynb\n",
    " - 採択年度の研究機関\n",
    "- parse_grantaward_member_from_summary.ipynb　←いまここ\n",
    " - 採択年度の研究代表者\n",
    "\n",
    "#### 課題番号をキーにして、3つの部品を統合して一つのテーブルを作る\n",
    "- parse_grantaward_integration.ipynb\n",
    "\n",
    "### 事前準備\n",
    "- kaken_zenkadai_download.ipynbを実行して、./xmlフォルダにXMLファイルを保存しておいてください。\n",
    "- ここでは、2010年以降のデータを扱うことにしています。\n",
    "\n",
    "### 使い方\n",
    "\n",
    "- 部品を作る3つのファイルを適宜の順序で実行します。それぞれから、./afterCleaningフォルダにデータフレーム（部品）が作られ、pickle形式でファイルを保存します。\n",
    " - parse_kadai.dump\n",
    " - parse_institution_from_grantlist.dump\n",
    " - parse_member_from_summary.dump\n",
    "- 3つの部品ができたら、parse_grantaward_integration.ipynbを実行すると、一つのテーブルに結合してローカルのMariaDBに保存されます。\n",
    "\n",
    "### 今後の予定\n",
    "\n",
    "自分が眺めた範囲では、古い年代ほどデータの欠損など問題があって、前処理が必要な雰囲気なので、新しいところから始めました。時間をみつけて、2010年以前のデータもパースできるようにしたいと思っています。KAKENに研究者番号が入っているのが1985年以降なので、優先順位としてはそこが一つの境目になると思っています。84年以前は、必要に応じてやりましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding: utf-8\n",
    "from lxml import etree\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 研究者を抽出する関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "研究者情報は、grantAward/summary/memberとgrantAward/memberList/memberの2箇所にある。前者は同じ人は複数出てこなくてまとまっているが、所属機関等のコードがない。後者は所属機関コードがあるが、毎年度の実績報告書があるので同じ人が複数回出てくる。差し当たって前者からデータを取得することにする。そのうち余裕が出たら、後者のデータと突合したい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def member(xmlfile):\n",
    "    tree = etree.parse(xmlfile)\n",
    "    nsmap = {\"xml\": \"http://www.w3.org/XML/1998/namespace\"}\n",
    "    memberlist = []\n",
    "    for grantAward in tree.iterfind(\"grantAward\"):\n",
    "        awardnumber = grantAward.get(\"awardNumber\")\n",
    "        for member in grantAward.find(\"summary[@xml:lang='ja']\", nsmap).iterfind(\"member\", nsmap):\n",
    "            sequence = member.get(\"sequence\")\n",
    "            role = member.get(\"role\")\n",
    "            kenkyuusha_id = member.get(\"eradCode\")\n",
    "\n",
    "            try:\n",
    "                familyname = member.find(\"personalName/familyName\").text\n",
    "            except:\n",
    "                familyname = np.NaN\n",
    "\n",
    "            try:\n",
    "                givenname = member.find(\"personalName/givenName\").text\n",
    "            except:\n",
    "                givenname = np.NaN\n",
    "\n",
    "            row = [\n",
    "                awardnumber,\n",
    "                sequence,\n",
    "                role,\n",
    "                kenkyuusha_id,\n",
    "                familyname,\n",
    "                givenname,\n",
    "            ]\n",
    "            memberlist.append(row)\n",
    "\n",
    "    df = pd.DataFrame(memberlist)\n",
    "    df.columns = [\n",
    "        'awardnumber',\n",
    "        'sequence',\n",
    "        'role',\n",
    "        'kenkyuusha_id',\n",
    "        'familyname',\n",
    "        'givenname',\n",
    "    ]\n",
    "\n",
    "    pickledfile = 'pickledDF_member_from_summary/' + re.search('[0-9]{4}_[0-9]+-[0-9]+.xml', xmlfile).group() + '.dump'\n",
    "    df.to_pickle(pickledfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フォルダをいったんきれいにする関数を定義して、実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def cleandir(dirname):\n",
    "    if os.path.isdir(dirname):\n",
    "        shutil.rmtree(dirname)\n",
    "    os.mkdir(dirname)\n",
    "\n",
    "cleandir('pickledDF_member_from_summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "関数を実行して、XMLファイルごとにパースして、pickleして保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xmlfile in tqdm(glob.glob('xml/201*.xml')):\n",
    "    member(xmlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'awardnumber',\n",
    "    'sequence',\n",
    "    'role',\n",
    "    'kenkyuusha_id',\n",
    "    'familyname',\n",
    "    'givenname',\n",
    "]\n",
    "df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dump in tqdm(glob.glob('pickledDF_member_from_summary/*.dump')):\n",
    "    with open(dump, mode='rb') as f:\n",
    "        df = pd.concat([df, pickle.load(f)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "連結したデータフレームをいったんpickleして保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('beforeCleaning/parse_member_from_summary.dump')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データクリーニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickleからデータフレームを復元する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('beforeCleaning/parse_member_from_summary.dump', mode='rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データフレームの構造を概観する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "研究者番号のルールに合わないもの（数字以外の文字が含まれているもの）を抽出する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、インデックスをリセットしておく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['kenkyuusha_id'].str.match('^[0-9]*$').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falseが2件あった。Falseのindexを抽出して、データフレームで表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "falselist = df['kenkyuusha_id'].str.match('^[0-9]*$')\n",
    "falselist = list(falselist[falselist == False].index)\n",
    "df.loc[falselist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KAKENやresearchmapで個人名で検索して正当な研究者番号に置換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.kenkyuusha_id.replace('235000 6', 50004619, inplace=True)\n",
    "#df.kenkyuusha_id.replace('2033+220', 80224103, inplace=True)\n",
    "#df.kenkyuusha_id.replace('A9406506', 10226110, inplace=True)\n",
    "df.kenkyuusha_id.replace('08J05773', 50571535, inplace=True)\n",
    "df.kenkyuusha_id.replace('12J00079', 40737251, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[falselist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({\n",
    "    'sequence': np.int64,\n",
    "    'kenkyuusha_id': np.int64,\n",
    "})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重複があるか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "role の件数を確認しておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.role.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "roleの対訳\n",
    "\n",
    "|role|対訳|\n",
    "|:---|:---|\n",
    "|principal_investigator|研究代表者|\n",
    "|co_investigator_buntan|研究分担者|\n",
    "|co_investigator_renkei|連携研究者|\n",
    "|research_collaborator|研究協力者|\n",
    "|research_fellow|特別研究員奨励費 特別研究員|\n",
    "|foreign_research_fellow|特別研究員奨励費 外国人特別研究員|\n",
    "|host_researcher|特別研究員奨励費 受入研究者|\n",
    "|area_organizer|特定領域研究、新学術領域研究(研究領域提案型) 領域代表者|\n",
    "|co_investigator_buntan_support|新学術領域研究（研究領域提案型）『学術研究支援基盤形成』 研究支援分担者|\n",
    "|principal_investigator_support|新学術領域研究（研究領域提案型）『学術研究支援基盤形成』 研究支援代表者|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roleから次のものだけ抽出\n",
    "\n",
    "- 研究代表者、\n",
    "- 特定領域研究、新学術領域研究(研究領域提案型) 領域代表者、\n",
    "- 新学術領域研究（研究領域提案型）『学術研究支援基盤形成』 研究支援代表者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['role'] == 'principal_investigator') | (df['role'] == 'area_organizer') | (df['role'] == 'principal_investigator_support')]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "awardnumberごとにsequenceが最大のレコードのみ抽出する。生のXMLを眺めてみると、sequenceが大きいほど古い年度のデータなので。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seqmax = df.groupby('awardnumber')['sequence'].max().reset_index()\n",
    "seqmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "awardnumberがユニークかどうか確認するために、行数234177とawardnumberのユニークな値の数が一致するかどうか確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seqmax['awardnumber'].nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "awardnumberがユニークになった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(seqmax, df, on=['awardnumber', 'sequence'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqmax['awardnumber'].nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "awardnumberはユニークだったので（ユニークじゃなかったら何かが違う）、インデックスにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('awardnumber')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('afterCleaning/parse_member_from_summary.dump')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ひとまず終了。\n",
    "\n",
    "次は、parse_grantaward_integration.ipynbで3つの部品を統合する。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
